{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570bb0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from speech_modeling import h_model, h_input\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1834a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gmu_scraping import getFiles\n",
    "\n",
    "# getFiles().get_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5db9163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           value              \\\n",
      "variable                                                      F1               \n",
      "word                                                           a               \n",
      "phoneme                                                      AH0         EY1   \n",
      "id         gender age location                                                 \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     484.116707    0.000000   \n",
      "english10  f      35  davenport_iowa_usa              446.479293    0.000000   \n",
      "english101 f      18  toronto_ontario_canada          500.414386    0.000000   \n",
      "english102 m      22  torrington_connecticut_usa      454.650048    0.000000   \n",
      "english103 m      21  statenisland_newyork_usa        440.677259    0.000000   \n",
      "...                                                          ...         ...   \n",
      "english95  m      18  mishawaka_indiana_usa           373.439207  436.228222   \n",
      "english96  m      31  pointpleasant_newjersey_usa     382.289638    0.000000   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  412.892373    0.000000   \n",
      "english98  m      22  spokane_washington_usa          418.064048    0.000000   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     457.689771    0.000000   \n",
      "\n",
      "                                                                              \\\n",
      "variable                                                                       \n",
      "word                                                        also               \n",
      "phoneme                                                      AO1           L   \n",
      "id         gender age location                                                 \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     649.691041  669.687544   \n",
      "english10  f      35  davenport_iowa_usa              805.901930  558.646929   \n",
      "english101 f      18  toronto_ontario_canada          681.140780  673.199329   \n",
      "english102 m      22  torrington_connecticut_usa      597.563789  568.951003   \n",
      "english103 m      21  statenisland_newyork_usa        570.352779  568.339030   \n",
      "...                                                          ...         ...   \n",
      "english95  m      18  mishawaka_indiana_usa           552.856185  536.275567   \n",
      "english96  m      31  pointpleasant_newjersey_usa     504.845230  556.576476   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  645.888058  700.158147   \n",
      "english98  m      22  spokane_washington_usa          618.866782  617.953326   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     749.402885  769.831476   \n",
      "\n",
      "                                                                               \\\n",
      "variable                                                                        \n",
      "word                                                                            \n",
      "phoneme                                                      OW0            S   \n",
      "id         gender age location                                                  \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     479.885272   828.677910   \n",
      "english10  f      35  davenport_iowa_usa              462.684377  1637.447390   \n",
      "english101 f      18  toronto_ontario_canada          457.321222   696.700079   \n",
      "english102 m      22  torrington_connecticut_usa      485.040418  1076.151878   \n",
      "english103 m      21  statenisland_newyork_usa        367.708427  1110.484311   \n",
      "...                                                          ...          ...   \n",
      "english95  m      18  mishawaka_indiana_usa           413.165623   793.053304   \n",
      "english96  m      31  pointpleasant_newjersey_usa     423.650958   772.147145   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  482.797701  1225.992121   \n",
      "english98  m      22  spokane_washington_usa          286.899709   275.746844   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     454.965281   717.069691   \n",
      "\n",
      "                                                                               \\\n",
      "variable                                                                        \n",
      "word                                                         and                \n",
      "phoneme                                                      AE1          AH0   \n",
      "id         gender age location                                                  \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     633.160121   567.639486   \n",
      "english10  f      35  davenport_iowa_usa              594.366055   471.828542   \n",
      "english101 f      18  toronto_ontario_canada          624.759445     0.000000   \n",
      "english102 m      22  torrington_connecticut_usa        0.000000   448.358869   \n",
      "english103 m      21  statenisland_newyork_usa        542.836571     0.000000   \n",
      "...                                                          ...          ...   \n",
      "english95  m      18  mishawaka_indiana_usa           462.244063   427.028355   \n",
      "english96  m      31  pointpleasant_newjersey_usa     609.150271     0.000000   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  892.139839  1773.535156   \n",
      "english98  m      22  spokane_washington_usa            0.000000   553.390182   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     517.224147   551.620150   \n",
      "\n",
      "                                                                              \\\n",
      "variable                                                                       \n",
      "word                                                                           \n",
      "phoneme                                                        D           N   \n",
      "id         gender age location                                                 \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     401.396704  428.132173   \n",
      "english10  f      35  davenport_iowa_usa              329.241046  415.977904   \n",
      "english101 f      18  toronto_ontario_canada          476.532053  526.467925   \n",
      "english102 m      22  torrington_connecticut_usa      351.509291  406.301128   \n",
      "english103 m      21  statenisland_newyork_usa        298.619690  456.744494   \n",
      "...                                                          ...         ...   \n",
      "english95  m      18  mishawaka_indiana_usa           326.855455  431.387578   \n",
      "english96  m      31  pointpleasant_newjersey_usa     480.844344  438.094412   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  420.303654  460.539344   \n",
      "english98  m      22  spokane_washington_usa          316.696529  407.752721   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     419.097745  476.334278   \n",
      "\n",
      "                                                      ...                  \\\n",
      "variable                                              ...  duration         \n",
      "word                                                  ... wednesday  will   \n",
      "phoneme                                               ...         Z   AH0   \n",
      "id         gender age location                        ...                   \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     ...      0.05  0.02   \n",
      "english10  f      35  davenport_iowa_usa              ...      0.10  0.02   \n",
      "english101 f      18  toronto_ontario_canada          ...      0.10  0.02   \n",
      "english102 m      22  torrington_connecticut_usa      ...      0.07  0.02   \n",
      "english103 m      21  statenisland_newyork_usa        ...      0.03  0.02   \n",
      "...                                                   ...       ...   ...   \n",
      "english95  m      18  mishawaka_indiana_usa           ...      0.08  0.02   \n",
      "english96  m      31  pointpleasant_newjersey_usa     ...      0.07  0.02   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  ...      0.07  0.02   \n",
      "english98  m      22  spokane_washington_usa          ...      0.08  0.02   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     ...      0.09  0.02   \n",
      "\n",
      "                                                                             \\\n",
      "variable                                                                      \n",
      "word                                                                   with   \n",
      "phoneme                                               IH1     L     W    DH   \n",
      "id         gender age location                                                \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     0.0  0.05  0.07  0.00   \n",
      "english10  f      35  davenport_iowa_usa              0.0  0.04  0.05  0.00   \n",
      "english101 f      18  toronto_ontario_canada          0.0  0.05  0.03  0.00   \n",
      "english102 m      22  torrington_connecticut_usa      0.0  0.04  0.03  0.03   \n",
      "english103 m      21  statenisland_newyork_usa        0.0  0.04  0.06  0.00   \n",
      "...                                                   ...   ...   ...   ...   \n",
      "english95  m      18  mishawaka_indiana_usa           0.0  0.05  0.08  0.00   \n",
      "english96  m      31  pointpleasant_newjersey_usa     0.0  0.04  0.03  0.00   \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  0.0  0.04  0.06  0.00   \n",
      "english98  m      22  spokane_washington_usa          0.0  0.03  0.04  0.00   \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     0.0  0.06  0.05  0.00   \n",
      "\n",
      "                                                                              \n",
      "variable                                                                      \n",
      "word                                                                          \n",
      "phoneme                                                IH0   IH1    TH     W  \n",
      "id         gender age location                                                \n",
      "english1   m      42  pittsburgh_pennsylvania_usa     0.05  0.00  0.08  0.09  \n",
      "english10  f      35  davenport_iowa_usa              0.05  0.00  0.12  0.04  \n",
      "english101 f      18  toronto_ontario_canada          0.00  0.04  0.11  0.03  \n",
      "english102 m      22  torrington_connecticut_usa      0.04  0.00  0.00  0.05  \n",
      "english103 m      21  statenisland_newyork_usa        0.04  0.00  0.05  0.07  \n",
      "...                                                    ...   ...   ...   ...  \n",
      "english95  m      18  mishawaka_indiana_usa           0.05  0.00  0.11  0.07  \n",
      "english96  m      31  pointpleasant_newjersey_usa     0.04  0.00  0.09  0.03  \n",
      "english97  m      42  wilmingtonnc_northcarolina_usa  0.03  0.00  0.05  0.03  \n",
      "english98  m      22  spokane_washington_usa          0.05  0.00  0.12  0.04  \n",
      "english99  f      52  pittsburgh_pennsylvania_usa     0.04  0.00  0.09  0.04  \n",
      "\n",
      "[640 rows x 1648 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-a-AH0</th>\n",
       "      <th>F1-a-EY1</th>\n",
       "      <th>F1-also-AO1</th>\n",
       "      <th>F1-also-OW0</th>\n",
       "      <th>F1-and-AE1</th>\n",
       "      <th>F1-and-AH0</th>\n",
       "      <th>F1-ask-AE1</th>\n",
       "      <th>F1-at-AE1</th>\n",
       "      <th>F1-bags-AE1</th>\n",
       "      <th>F1-big-IH1</th>\n",
       "      <th>...</th>\n",
       "      <th>F1-toy-OY1</th>\n",
       "      <th>F1-train-EY1</th>\n",
       "      <th>F1-we-IY1</th>\n",
       "      <th>F1-wednesday-EH1</th>\n",
       "      <th>F1-wednesday-EY2</th>\n",
       "      <th>F1-wednesday-IY0</th>\n",
       "      <th>F1-will-AH0</th>\n",
       "      <th>F1-will-IH1</th>\n",
       "      <th>F1-with-IH0</th>\n",
       "      <th>F1-with-IH1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>484.116707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>649.691041</td>\n",
       "      <td>479.885272</td>\n",
       "      <td>633.160121</td>\n",
       "      <td>567.639486</td>\n",
       "      <td>744.763339</td>\n",
       "      <td>539.505943</td>\n",
       "      <td>650.597091</td>\n",
       "      <td>418.221579</td>\n",
       "      <td>...</td>\n",
       "      <td>558.103092</td>\n",
       "      <td>598.918749</td>\n",
       "      <td>388.760823</td>\n",
       "      <td>659.521692</td>\n",
       "      <td>428.807428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>458.317544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>451.351407</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>446.479293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>805.901930</td>\n",
       "      <td>462.684377</td>\n",
       "      <td>594.366055</td>\n",
       "      <td>471.828542</td>\n",
       "      <td>767.568712</td>\n",
       "      <td>625.072530</td>\n",
       "      <td>854.488527</td>\n",
       "      <td>469.280507</td>\n",
       "      <td>...</td>\n",
       "      <td>526.556666</td>\n",
       "      <td>389.303757</td>\n",
       "      <td>429.566074</td>\n",
       "      <td>562.260227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>371.502363</td>\n",
       "      <td>376.116950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.187307</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500.414386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>681.140780</td>\n",
       "      <td>457.321222</td>\n",
       "      <td>624.759445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>783.014323</td>\n",
       "      <td>688.876577</td>\n",
       "      <td>727.667387</td>\n",
       "      <td>551.872631</td>\n",
       "      <td>...</td>\n",
       "      <td>588.790482</td>\n",
       "      <td>494.794385</td>\n",
       "      <td>464.039105</td>\n",
       "      <td>628.624622</td>\n",
       "      <td>573.865729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>419.221923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>533.898484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454.650048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>597.563789</td>\n",
       "      <td>485.040418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>448.358869</td>\n",
       "      <td>721.693053</td>\n",
       "      <td>486.496701</td>\n",
       "      <td>621.065208</td>\n",
       "      <td>408.205085</td>\n",
       "      <td>...</td>\n",
       "      <td>486.987983</td>\n",
       "      <td>500.964263</td>\n",
       "      <td>363.266894</td>\n",
       "      <td>608.917180</td>\n",
       "      <td>516.772289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>455.938218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.447378</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>440.677259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>570.352779</td>\n",
       "      <td>367.708427</td>\n",
       "      <td>542.836571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>531.205255</td>\n",
       "      <td>439.593369</td>\n",
       "      <td>510.274918</td>\n",
       "      <td>396.962703</td>\n",
       "      <td>...</td>\n",
       "      <td>462.312784</td>\n",
       "      <td>551.478720</td>\n",
       "      <td>324.386679</td>\n",
       "      <td>550.618805</td>\n",
       "      <td>448.772615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>377.056530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>439.580531</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>373.439207</td>\n",
       "      <td>436.228222</td>\n",
       "      <td>552.856185</td>\n",
       "      <td>413.165623</td>\n",
       "      <td>462.244063</td>\n",
       "      <td>427.028355</td>\n",
       "      <td>581.437571</td>\n",
       "      <td>554.111796</td>\n",
       "      <td>620.117427</td>\n",
       "      <td>409.366342</td>\n",
       "      <td>...</td>\n",
       "      <td>468.141905</td>\n",
       "      <td>400.395679</td>\n",
       "      <td>346.698229</td>\n",
       "      <td>442.615747</td>\n",
       "      <td>450.836784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>406.173443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>404.690474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>382.289638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>504.845230</td>\n",
       "      <td>423.650958</td>\n",
       "      <td>609.150271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>628.395514</td>\n",
       "      <td>492.388026</td>\n",
       "      <td>584.881696</td>\n",
       "      <td>384.790654</td>\n",
       "      <td>...</td>\n",
       "      <td>438.897814</td>\n",
       "      <td>353.606437</td>\n",
       "      <td>319.910994</td>\n",
       "      <td>540.039985</td>\n",
       "      <td>440.448956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>344.062611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.992729</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>412.892373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>645.888058</td>\n",
       "      <td>482.797701</td>\n",
       "      <td>892.139839</td>\n",
       "      <td>1773.535156</td>\n",
       "      <td>676.025798</td>\n",
       "      <td>479.539749</td>\n",
       "      <td>658.410675</td>\n",
       "      <td>421.701828</td>\n",
       "      <td>...</td>\n",
       "      <td>629.698310</td>\n",
       "      <td>546.900984</td>\n",
       "      <td>303.396840</td>\n",
       "      <td>644.298475</td>\n",
       "      <td>406.628629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>698.005034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>446.082325</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>418.064048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>618.866782</td>\n",
       "      <td>286.899709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>553.390182</td>\n",
       "      <td>694.308547</td>\n",
       "      <td>363.337824</td>\n",
       "      <td>635.685699</td>\n",
       "      <td>408.574349</td>\n",
       "      <td>...</td>\n",
       "      <td>463.550769</td>\n",
       "      <td>366.878979</td>\n",
       "      <td>360.733320</td>\n",
       "      <td>401.566298</td>\n",
       "      <td>408.769797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>359.815566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>430.033459</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>457.689771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>749.402885</td>\n",
       "      <td>454.965281</td>\n",
       "      <td>517.224147</td>\n",
       "      <td>551.620150</td>\n",
       "      <td>870.185432</td>\n",
       "      <td>604.466515</td>\n",
       "      <td>755.833263</td>\n",
       "      <td>472.077218</td>\n",
       "      <td>...</td>\n",
       "      <td>525.328010</td>\n",
       "      <td>585.561931</td>\n",
       "      <td>427.429606</td>\n",
       "      <td>613.993904</td>\n",
       "      <td>540.764886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>503.244400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.661997</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       F1-a-AH0    F1-a-EY1  F1-also-AO1  F1-also-OW0  F1-and-AE1  \\\n",
       "0    484.116707    0.000000   649.691041   479.885272  633.160121   \n",
       "1    446.479293    0.000000   805.901930   462.684377  594.366055   \n",
       "2    500.414386    0.000000   681.140780   457.321222  624.759445   \n",
       "3    454.650048    0.000000   597.563789   485.040418    0.000000   \n",
       "4    440.677259    0.000000   570.352779   367.708427  542.836571   \n",
       "..          ...         ...          ...          ...         ...   \n",
       "635  373.439207  436.228222   552.856185   413.165623  462.244063   \n",
       "636  382.289638    0.000000   504.845230   423.650958  609.150271   \n",
       "637  412.892373    0.000000   645.888058   482.797701  892.139839   \n",
       "638  418.064048    0.000000   618.866782   286.899709    0.000000   \n",
       "639  457.689771    0.000000   749.402885   454.965281  517.224147   \n",
       "\n",
       "      F1-and-AH0  F1-ask-AE1   F1-at-AE1  F1-bags-AE1  F1-big-IH1  ...  \\\n",
       "0     567.639486  744.763339  539.505943   650.597091  418.221579  ...   \n",
       "1     471.828542  767.568712  625.072530   854.488527  469.280507  ...   \n",
       "2       0.000000  783.014323  688.876577   727.667387  551.872631  ...   \n",
       "3     448.358869  721.693053  486.496701   621.065208  408.205085  ...   \n",
       "4       0.000000  531.205255  439.593369   510.274918  396.962703  ...   \n",
       "..           ...         ...         ...          ...         ...  ...   \n",
       "635   427.028355  581.437571  554.111796   620.117427  409.366342  ...   \n",
       "636     0.000000  628.395514  492.388026   584.881696  384.790654  ...   \n",
       "637  1773.535156  676.025798  479.539749   658.410675  421.701828  ...   \n",
       "638   553.390182  694.308547  363.337824   635.685699  408.574349  ...   \n",
       "639   551.620150  870.185432  604.466515   755.833263  472.077218  ...   \n",
       "\n",
       "     F1-toy-OY1  F1-train-EY1   F1-we-IY1  F1-wednesday-EH1  F1-wednesday-EY2  \\\n",
       "0    558.103092    598.918749  388.760823        659.521692        428.807428   \n",
       "1    526.556666    389.303757  429.566074        562.260227          0.000000   \n",
       "2    588.790482    494.794385  464.039105        628.624622        573.865729   \n",
       "3    486.987983    500.964263  363.266894        608.917180        516.772289   \n",
       "4    462.312784    551.478720  324.386679        550.618805        448.772615   \n",
       "..          ...           ...         ...               ...               ...   \n",
       "635  468.141905    400.395679  346.698229        442.615747        450.836784   \n",
       "636  438.897814    353.606437  319.910994        540.039985        440.448956   \n",
       "637  629.698310    546.900984  303.396840        644.298475        406.628629   \n",
       "638  463.550769    366.878979  360.733320        401.566298        408.769797   \n",
       "639  525.328010    585.561931  427.429606        613.993904        540.764886   \n",
       "\n",
       "     F1-wednesday-IY0  F1-will-AH0  F1-will-IH1  F1-with-IH0  F1-with-IH1  \n",
       "0            0.000000   458.317544          0.0   451.351407     0.000000  \n",
       "1          371.502363   376.116950          0.0   450.187307     0.000000  \n",
       "2            0.000000   419.221923          0.0     0.000000   533.898484  \n",
       "3            0.000000   455.938218          0.0   450.447378     0.000000  \n",
       "4            0.000000   377.056530          0.0   439.580531     0.000000  \n",
       "..                ...          ...          ...          ...          ...  \n",
       "635          0.000000   406.173443          0.0   404.690474     0.000000  \n",
       "636          0.000000   344.062611          0.0   403.992729     0.000000  \n",
       "637          0.000000   698.005034          0.0   446.082325     0.000000  \n",
       "638          0.000000   359.815566          0.0   430.033459     0.000000  \n",
       "639          0.000000   503.244400          0.0   450.661997     0.000000  \n",
       "\n",
       "[640 rows x 80 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(\"./formants.csv\")\n",
    "input_data = h_input(raw_df)\n",
    "input_data.process()\n",
    "input_data.revert()\n",
    "input_data.input_df[input_data.f1v_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553454d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_country(location):\n",
    "    l_list = location.split(\"_\")\n",
    "    if len(l_list) > 2:\n",
    "        return l_list[2]\n",
    "    elif len(l_list) > 1:\n",
    "        return l_list[1]\n",
    "    else:\n",
    "        return l_list[0]\n",
    "    \n",
    "def extract_place(location):\n",
    "    l_list = location.split(\"_\")\n",
    "    if len(l_list) > 1:\n",
    "        return l_list[1]\n",
    "    else:\n",
    "        return l_list[0]\n",
    "\n",
    "def word_find(feature):\n",
    "    return feature.split(\"-\")[0][0:2] + \"-\" + feature.split(\"-\")[1]\n",
    "\n",
    "dem_feats = ['age','gender']\n",
    "in_df = input_data.input_df\n",
    "in_df['location'] = in_df['location'].apply(extract_place)\n",
    "in_df.gender = in_df.gender.replace(to_replace=['m', 'f'], value=[1, 0])\n",
    "in_df['age'] = pd.to_numeric(in_df['age'])\n",
    "\n",
    "opt_df = in_df.copy()[['id','gender','age','location']]\n",
    "\n",
    "words = [word_find(f) for f in in_df.columns[4:]]\n",
    "for w in words:\n",
    "    for c in in_df.columns[4:]:\n",
    "        if word_find(c) == w:\n",
    "            opt_df[w] = in_df[c]\n",
    "            break\n",
    "\n",
    "in_list = list(in_df.columns[4:])\n",
    "opt_list = list(opt_df.columns[4:])\n",
    "for f in range(len(opt_list)):\n",
    "    for s in range(len(opt_df)):\n",
    "        if opt_df.iloc[s, f+4] == 0:\n",
    "            for i in range(len(in_list)):\n",
    "                word = word_find(in_list[i])\n",
    "                if word == opt_list[f]:\n",
    "                    if in_df.iloc[s, i+4] != 0.0:\n",
    "                        opt_df.iloc[s, f+4] = in_df.iloc[s,i+4]\n",
    "                        break\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c9968f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'F2-a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3790\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3791\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'F2-a'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_922100/863389594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"F2-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mopt_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3795\u001b[0m             ):\n\u001b[1;32m   3796\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3797\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3798\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3799\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'F2-a'"
     ]
    }
   ],
   "source": [
    "#normalize and filter for particular locations\n",
    "new_df = opt_df.copy()[['id','gender','age','location']]\n",
    "not_features = list(opt_df.columns)[0:4]\n",
    "\n",
    "for c in opt_df.columns[4:]:\n",
    "    if c[0:2] == \"F1\":\n",
    "        name = \"F1mF2\" + c[2:]\n",
    "        word = c.split(\"-\")[1]\n",
    "        c2 = \"F2-\" + word\n",
    "        new_df[name] = opt_df[c2] - opt_df[c]\n",
    "        \n",
    "fs = list(new_df.columns)[4:]\n",
    "\n",
    "for column in fs: \n",
    "#     new_df[column]=(new_df[column]-new_df[column].mean())/new_df[column].std()\n",
    "    new_df[column]=(new_df[column]-new_df[column].min())/(new_df[column].max()-new_df[column].min())\n",
    "\n",
    "opt_df = pd.merge(opt_df[not_features], new_df[fs], left_index=True, right_index=True)\n",
    "\n",
    "places = [\"uk\", \"texas\", \"california\", \"washington\", \"oregon\", \"colorado\", \"minnesota\", \"wisconsin\", \"illinois\",\n",
    "         \"maine\"]\n",
    "\n",
    "filtered_df = opt_df.loc[opt_df['location'].isin(places)].reset_index(drop=True)\n",
    "\n",
    "used_features = [f for f in list(filtered_df.columns[4:]) if f[0:5] in [\"F1mF2\"]]\n",
    "filtered_features = dem_feats + used_features\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ee64bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model of type rforest\n",
      "Modeling Sample 1 of 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot perform LeaveOneOut with n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_922100/3547568982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltered_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_main\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_SAMPLES\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/senior-thesis/corpus-testing/speech_modeling.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model_type, NUM_SAMPLES)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Modeling Sample {i+1} of {NUM_SAMPLES}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m#loop over every split and make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mxtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mytrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mBy\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelegates\u001b[0m \u001b[0mto\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mtest_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0;34m\"Cannot perform LeaveOneOut with n_samples={}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot perform LeaveOneOut with n_samples=0."
     ]
    }
   ],
   "source": [
    "m = h_model(data=filtered_df, features=filtered_features, y_feature=\"location\", y_main=\"uk\")\n",
    "m.fit(NUM_SAMPLES=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = h_model(data=filtered_df, features=filtered_features, y_feature=\"location\", y_main=\"texas\")\n",
    "m2.fit(model_type=\"ridge_classification\", NUM_SAMPLES=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
